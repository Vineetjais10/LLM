## Report on Fine-Tuning a Multi-Modal Model on a Medical Imaging Dataset
# Introduction:
The aim of this report is to outline the process of fine-tuning a multi-modal model, specifically LLaVA (Language Learning with Vision and Audio), on a medical imaging dataset. We selected the MIMIC-CXR dataset from Kaggle, which includes chest X-ray images and associated radiology reports.

Dataset Selection
Dataset: MIMIC-CXR
Source: Kaggle - MIMIC-CXR Dataset

Content:

Images: Over 350,000 chest X-ray images.
Text: Corresponding radiology reports providing textual descriptions of the findings.
